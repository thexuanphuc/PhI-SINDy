{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from csv import DictWriter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from itertools import combinations_with_replacement\n",
    "from itertools import chain\n",
    "\n",
    "import torch_optimizer as optim_all\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams['text.usetex'] = False\n",
    "from result_utils import *\n",
    "from manual_sindy import *\n",
    "from gendata import *   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randSeed = 42\n",
    "\n",
    "T.manual_seed(randSeed)\n",
    "np.random.seed(seed=randSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class parameters:\n",
    "    # Learning hyperparameters\n",
    "    num_epochs = 1000\n",
    "    num_iter = 3\n",
    "    lr = 1e-1\n",
    "    weightdecay = 0.0\n",
    "    tol_coeffs: float = 1e-1\n",
    "    scaling: bool = True\n",
    "    scale_angle = 100.0\n",
    "\n",
    "    # parameters for system with known dynamics\n",
    "    m1: float = 1.0\n",
    "    m2: float = 1.0\n",
    "    c1_external: float = 0.1    # for all external force\n",
    "    c2_external: float = 0.1    # for all external force\n",
    "\n",
    "    # input signal\n",
    "    freq1: float = 0.6\n",
    "    freq2: float = 0.0\n",
    "    F1: float = 1.0\n",
    "    F2: float = 0.0\n",
    "    phi: float = 0.0\n",
    "\n",
    "    # TODO: how to use multiple trajectories\n",
    "    timestep: float = 1e-2\n",
    "    timefinal: float = 50.0\n",
    "    x0: tuple = (0.0, 0.0, 0.0, 0.0)\n",
    "\n",
    "    save_analysis = False \n",
    "    \n",
    "    # [x, y, theta, vx, vy, omega] -> only 3 equations\n",
    "    n_eqs: int = 3\n",
    "    \n",
    "    # Assumed features\n",
    "    poly_order: int = 2\n",
    "    # cos_phases: np.ndarray = np.arange(0.9, 1.51, 0.3)\n",
    "    cos_phases: np.ndarray = ()\n",
    "    # y1_sgn_flag: bool = False  #we have used the sign in RK4, not need more feature here  \n",
    "    # y2_sgn_flag: bool = False  #we have used the sign in RK4, not need more feature here  \n",
    "    log_1_fr1: bool = False\n",
    "    log_2_fr1: bool = False\n",
    "    log_1_fr2: bool = False\n",
    "    log_2_fr2: bool = False\n",
    "    \n",
    "Params = parameters()\n",
    "\n",
    "# addtional parameters for friction (should be the same for x,y)\n",
    "Params.frx: dict = {'DR_flag' : False, 'friction_force_ratio' : 0.5, 'a': 0.07, 'b': 0.09, 'c': 0.022, 'V_star': 0.003, 'eps': 1e-6}\n",
    "Params.fry: dict = {'DR_flag' : False, 'friction_force_ratio' : 0.5, 'a': 0.07, 'b': 0.09, 'c': 0.022, 'V_star': 0.003, 'eps': 1e-6}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, x_denoised = generate_data(Params)\n",
    "\n",
    "#Generate noisy measurements\n",
    "if Params.noisy_measure_flag:\n",
    "    x = np.random.normal(loc=x_denoised, scale=Params.noise_level * np.abs(x_denoised), size=x_denoised.shape)\n",
    "else:\n",
    "    x = x_denoised\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn sparse solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Params.scaling:\n",
    "    Params.mus = T.tensor(np.mean(x, axis=0)).float().unsqueeze(0)\n",
    "    Params.stds = T.tensor(np.std(x, axis=0)).float().unsqueeze(0)\n",
    "\n",
    "# Learn the coefficients\n",
    "train_dset = T.tensor(x).float()\n",
    "times = T.tensor(ts).unsqueeze(1).float()\n",
    "\n",
    "no_of_terms = apply_features(train_dset[:2], times[:2], params=Params).shape[1]\n",
    "\n",
    "coeffs = CoeffsDictionary(no_of_terms, Params.n_eqs)\n",
    "\n",
    "# Learning Coefficients\n",
    "coeffs, loss_track = learn_sparse_model(coeffs, train_dset, times, Params, lr_reduction=10)\n",
    "\n",
    "# TODO: how to interpret this coefficients\n",
    "learnt_coeffs = coeffs.linear.weight.detach().clone().t().numpy()\n",
    "\n",
    "print()\n",
    "print(learnt_coeffs)\n",
    "# equation = print_learnt_equation(lrcfs, Params)\n",
    "\n",
    "# print(f\"\\n\\n{'-' * len(equation)}\\n{'The learnt equation is:'.center(len(equation))}\\n{equation}\\n{'-' * len(equation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnt_model(x, t, learnt_coeffs, params):\n",
    "    identified = (apply_features(np.expand_dims(x, axis=0), t, params=params, torch_flag=False) @ learnt_coeffs)[0]\n",
    "    \n",
    "    derivs = np.array([x[2],\n",
    "                       x[3],\n",
    "                       - (params.k1 + params.k2) / params.m1 * x[0] \n",
    "                       - (params.c1 + params.c2) / params.m1 * x[2] \n",
    "                       + params.k2 / params.m1 * x[1] \n",
    "                       + params.c2 / params.m1 * x[3] \n",
    "                       + params.F1 / params.m1 * np.cos(params.freq1 * t)\n",
    "                       + identified[0] * np.sign(x[2]),\n",
    "                       - params.k2 / params.m2 * x[1] \n",
    "                       - params.c2 / params.m2 * x[3] \n",
    "                       + params.k2 / params.m2 * x[0] \n",
    "                       + params.c2 / params.m2 * x[2] \n",
    "                       + params.F2 /params.m2 * np.cos(params.freq2 * (t + params.phi))\n",
    "                       + identified[1] * np.sign(x[3])], dtype=object)\n",
    "    \n",
    "    if (np.abs(x[2]) <= 1e-5) and (np.abs(params.F1 * np.cos(params.freq1 * t) + params.c2 * x[3] + params.k2 * x[1] - (params.k1 + params.k2) * x[0]) <= np.abs(identified[0])):\n",
    "        derivs[[0, 2]] = 0.\n",
    "    if (np.abs(x[3]) <= 1e-5) and (np.abs(params.c2 * x[2] + params.k2 * x[0] - params.k2 * x[1]) <= np.abs(identified[1])):\n",
    "        derivs[[1, 3]] = 0.\n",
    "\n",
    "    return derivs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data to be plotted\n",
    "sol_learnt = solve_ivp(lambda t, x: learnt_model(x, t, learnt_coeffs, Params), [ts[0], ts[-1]], Params.x0, t_eval=ts,)\n",
    "x_learnt = np.transpose(sol_learnt.y)\n",
    "\n",
    "# learnt_points = np.zeros_like(x)\n",
    "# learnt_points[0] = Params.x0\n",
    "\n",
    "# for k, t_ in enumerate(ts[1:], start=1):\n",
    "#     learnt_points[k] = rk4th_onestep(learnt_model, learnt_points[k-1], t_, learnt_coeffs, Params)\n",
    "\n",
    "Params.nrmse = np.sqrt(((x_denoised - x_learnt) ** 2).sum(axis=0) / x_learnt.shape[0]) / (x_denoised.max(axis=0) - x_denoised.min(axis=0))\n",
    "print(f\"NRMSE: {Params.nrmse}\")\n",
    "# Params.nrmse_2 = np.sqrt(((x_denoised - x_learnt) ** 2).sum(axis=0) / learnt_points.shape[0]) / (x_denoised.max(axis=0) - x_denoised.min(axis=0))\n",
    "# print(f\"NRMSE: {Params.nrmse_2}\")\n",
    "\n",
    "parent_dir = \"\\\\\\\\tudelft.net\\\\staff-homes\\\\L\\\\cllathourakis\\\\Desktop\\\\ResearchAssistant\\\\research\\\\code\\\\current\\\\Results\\\\Paper\"\n",
    "child_dir = os.path.join(parent_dir, '1')\n",
    "\n",
    "if False:\n",
    "    # Directories setup\n",
    "    setup_directories(child_dir)\n",
    "\n",
    "    # Save hyperparameters, coefficients and loss\n",
    "    store_results(Params, loss_track, learnt_coeffs, parent_dir, child_dir)\n",
    "\n",
    "y_labels = (r\"$x_1(t) \\, \\, \\mathrm{[m]}$\",\n",
    "            r\"$x_2(t) \\, \\, \\mathrm{[m]}$\",\n",
    "            r\"$\\dot{x}_1(t) \\, \\, \\mathrm{[m]}$\",\n",
    "            r\"$\\dot{x}_2(t) \\, \\, \\mathrm{[m]}$\")\n",
    "\n",
    "for c, label in enumerate(y_labels):\n",
    "    plot_results(ts, x_denoised[:, c], x[:, c], x_learnt[:, c], child_dir, y_label=label, save_flag=Params.save_analysis)\n",
    "\n",
    "# for c, t in enumerate(('d', 'v')):\n",
    "#     plot_results(ts, x_denoised[:, c], x[:, c], learnt_points[:, c], child_dir, type_flag=t, save_flag=Params.save_analysis)\n",
    "\n",
    "plot_error(ts, x_denoised, x_learnt, Params.nrmse, child_dir, type_flag='d', save_flag=Params.save_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 11\n",
    "tsize = 18\n",
    "\n",
    "tdir = 'in'\n",
    "\n",
    "major = 5.0\n",
    "minor = 3.0\n",
    "\n",
    "style = 'default'\n",
    "\n",
    "plt.style.use(style)\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams['font.size'] = fsize\n",
    "plt.rcParams['legend.fontsize'] = tsize\n",
    "plt.rcParams['xtick.direction'] = tdir\n",
    "plt.rcParams['ytick.direction'] = tdir\n",
    "plt.rcParams['xtick.major.size'] = major\n",
    "plt.rcParams['xtick.minor.size'] = minor\n",
    "plt.rcParams['ytick.major.size'] = major\n",
    "plt.rcParams['ytick.minor.size'] = minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data to be plotted\n",
    "sol_learnt_2 = solve_ivp(lambda t, x: learnt_model(x, t, learnt_coeffs, Params), [ts[0], ts[-1]], Params.x0, t_eval=ts,)\n",
    "x_learnt_2 = np.transpose(sol_learnt_2.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54\n",
    "_, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, figsize=(16*cm,16*cm), sharex=True)\n",
    "\n",
    "ax1.plot(ts, x_learnt_2[:, 0], \"k--\", linewidth=1, label='RK4-SINDy - With event condition')\n",
    "ax1.plot(ts, x_learnt[:, 0], \"k-.\", linewidth=1, alpha=0.5, label='RK4-SINDy - Without event condition')\n",
    "ax1.plot(ts, x_denoised[:, 0], linewidth=1.5, alpha=0.3, label='Ground Truth')\n",
    "# ax1.plot(ts[::100], x[::100, 0], \"ro\", markersize=2, label='Measurements')\n",
    "ax2.plot(ts, x_learnt_2[:, 1], \"k--\", linewidth=1, label='RK4-SINDy - With event condition')\n",
    "ax2.plot(ts, x_learnt[:, 1], \"k-.\", linewidth=1, alpha=0.5, label='RK4-SINDy - Without event condition')\n",
    "ax2.plot(ts, x_denoised[:, 1], linewidth=1.5, alpha=0.3, label='Ground Truth')\n",
    "# ax2.plot(ts[::100], x[::100, 1], \"ro\", markersize=2, linewidth=4, label='Measurements')\n",
    "ax3.plot(ts, x_learnt_2[:, 2], \"k--\", linewidth=1, label='RK4-SINDy - With event condition')\n",
    "ax3.plot(ts, x_learnt[:, 2], \"k-.\", linewidth=1, alpha=0.5, label='RK4-SINDy - Without event condition')\n",
    "ax3.plot(ts, x_denoised[:, 2], linewidth=1.5, alpha=0.3, label='Ground Truth')\n",
    "# ax3.plot(ts[::100], x[::100, 2], \"ro\", markersize=2, label='Measurements')\n",
    "ax4.plot(ts, x_learnt_2[:, 3], \"k--\", linewidth=1, label='RK4-SINDy - With event condition')\n",
    "ax4.plot(ts, x_learnt[:, 3], \"k-.\", linewidth=1, alpha=0.5, label='RK4-SINDy - Without event condition')\n",
    "ax4.plot(ts, x_denoised[:, 3], linewidth=1.5, alpha=0.3, label='Ground Truth')\n",
    "# ax4.plot(ts[::100], x[::100, 3], \"ro\", markersize=2, linewidth=4, label='Measurements')\n",
    "\n",
    "plt.xlabel(\"$t$ [s]\")\n",
    "ax1.set_ylabel(\"$x_1(t)$ [m]\")\n",
    "ax2.set_ylabel(\"$x_2(t)$ [m]\")\n",
    "ax3.set_ylabel(\"$\\dot{x}_1(t)$ [m/s]\")\n",
    "ax4.set_ylabel(\"$\\dot{x}_2(t)$ [m/s]\")\n",
    "\n",
    "\n",
    "ax4.set_xticks(np.arange(0, 51, 10), np.arange(0, 51, 10))\n",
    "ax1.set_yticks(np.arange(-2, 2.1, 1), np.arange(-2, 2.1, 1))\n",
    "ax2.set_yticks(np.arange(-2.5, 2.6, 1), np.arange(-2.5, 2.6, 1))\n",
    "ax3.set_yticks(np.arange(-1.0, 1.1, 0.5), np.arange(-1.0, 1.1, 0.5))\n",
    "ax4.set_yticks(np.arange(-2, 2.1, 1),np.arange(-2, 2.1, 1))\n",
    "\n",
    "ax1.set_ylim((-2, 2))\n",
    "ax2.set_ylim((-2.5, 2.5))\n",
    "ax3.set_ylim((-1, 1))\n",
    "ax4.set_ylim((-2, 2))\n",
    "# ax2.set_ylim((-0.05, 0.05))\n",
    "ax4.set_xlim((0, 50))\n",
    "# plt.legend(fontsize=20, bbox_to_anchor=(1., 5.1))\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 5.4), ncols=1, fontsize=11)#, handlelength =0.8, columnspacing=0.5, handletextpad=0.5)\n",
    "\n",
    "ax1.yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}')) \n",
    "ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}')) \n",
    "ax1.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n",
    "ax2.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n",
    "ax3.yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}')) \n",
    "ax4.yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}')) \n",
    "ax3.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n",
    "ax4.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}')) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
